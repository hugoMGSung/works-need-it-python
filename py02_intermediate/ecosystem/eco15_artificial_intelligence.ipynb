{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능 - 머신러닝/딥러닝\n",
    "\n",
    "### TensorFlow: Google이 개발한 오픈소스 머신 러닝 라이브러리\n",
    "\n",
    "- https://www.tensorflow.org/\n",
    "\n",
    "```shell\n",
    "# CPU 버전 설치\n",
    "pip install tensorflow\n",
    "\n",
    "# GPU 버전 설치\n",
    "pip install tensorflow-gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.17.1-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached grpcio-1.69.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached optree-0.13.1-cp310-cp310-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.69.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "Using cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.1-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.69.0 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.1\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.4918\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1511\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.1083\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0884\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0784\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07475703954696655, 0.9785000085830688]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # 정규화\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 모델 평가\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper: OpenAI에서 만든 자동 음성 인식\n",
    "\n",
    "- https://openai.com/index/whisper/\n",
    "\n",
    "자동 음성 인식(ASR)을 위한 강력한 라이브러리. OpenAI에 의해 개발되었으며, 커뮤니티에 널리 사용되고 있슴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "     ---------------------------------------- 0.0/800.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 800.5/800.5 kB 16.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from openai-whisper) (2.5.1)\n",
      "Requirement already satisfied: tqdm in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Using cached more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Using cached more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803407 sha256=324766ee2c687ba8f3fe015e2affa60cd4bd4cfca0bba96c9bd2ce56d72e5f2e\n",
      "  Stored in directory: c:\\users\\perso\\appdata\\local\\pip\\cache\\wheels\\dd\\4a\\1f\\d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: regex, more-itertools, tiktoken, openai-whisper\n",
      "Successfully installed more-itertools-10.5.0 openai-whisper-20240930 regex-2024.11.6 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 오디오 파일을 텍스트로 변환\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgirl_audio.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 변환된 텍스트 출력\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\whisper\\transcribe.py:133\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[0;32m    135\u001b[0m content_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(content_frames \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE)\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\subprocess.py:1440\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1440\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1456\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1457\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# 모델 로드\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# 오디오 파일을 텍스트로 변환\n",
    "result = model.transcribe(\"girl_audio.mp3\")\n",
    "\n",
    "# 변환된 텍스트 출력\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost: 향상된 그라디언트 부스팅 알고리즘\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/stable/\n",
    "\n",
    "향상된 그라디언트 부스팅 알고리즘을 구현한 라이브러리로, 분류, 회귀, 순위 결정 등 다양한 머신러닝 문제를 해결하는 데 널리 사용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from xgboost) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[13:20:05] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\file_iterator.cc:27: Check failed: name_args.size() == 2 (1 vs. 2) : URI parameter `format` is required for loading text data: filename?format=csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DMatrix, train\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 데이터 로드 및 DMatrix 형태로 변환\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train-svm.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m dtest \u001b[38;5;241m=\u001b[39m DMatrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/test-svm.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 파라미터 설정\u001b[39;00m\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\xgboost\\core.py:878\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\xgboost\\data.py:1189\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_numpy_array(\n\u001b[0;32m   1186\u001b[0m         data, missing, threads, feature_names, feature_types, data_split_mode\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_uri(data):\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data):\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_list(\n\u001b[0;32m   1192\u001b[0m         data, missing, threads, feature_names, feature_types, data_split_mode\n\u001b[0;32m   1193\u001b[0m     )\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\xgboost\\data.py:1089\u001b[0m, in \u001b[0;36m_from_uri\u001b[1;34m(data, missing, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[0;32m   1084\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(data),\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_split_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(data_split_mode),\n\u001b[0;32m   1087\u001b[0m }\n\u001b[0;32m   1088\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(args), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1089\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixCreateFromURI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handle, feature_names, feature_types\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [13:20:05] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\file_iterator.cc:27: Check failed: name_args.size() == 2 (1 vs. 2) : URI parameter `format` is required for loading text data: filename?format=csv"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix, train\n",
    "\n",
    "# 데이터 로드 및 DMatrix 형태로 변환\n",
    "dtrain = DMatrix('./data/train-svm.txt')\n",
    "dtest = DMatrix('./data/test-svm.txt')\n",
    "\n",
    "# 파라미터 설정\n",
    "param = {\n",
    "    'max_depth': 3,  # 트리의 최대 깊이\n",
    "    'eta': 0.3,      # 학습률\n",
    "    'objective': 'multi:softprob',  # 다중 클래스 분류\n",
    "    'num_class': 3   # 클래스 수\n",
    "}\n",
    "num_round = 20  # 부스팅 라운드 수\n",
    "\n",
    "# 모델 학습\n",
    "bst = train(param, dtrain, num_round)\n",
    "\n",
    "# 예측\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)\n",
    "# create model instance\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 0, 0, 2, 1, 2,\n",
       "       0, 0, 0, 0, 0, 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diffusers: 딥러닝 기반의 생성 모델 도구\n",
    "\n",
    "- https://huggingface.co/docs/diffusers/index\n",
    "\n",
    "Hugging Face에서 제공하는, 딥러닝 기반의 생성 모델을 쉽게 사용할 수 있게 해주는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "!pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: diffusers[torch] in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (0.33.0.dev0)\n",
      "Requirement already satisfied: importlib_metadata in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (8.5.0)\n",
      "Requirement already satisfied: filelock in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (0.27.1)\n",
      "Requirement already satisfied: numpy in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (0.5.2)\n",
      "Requirement already satisfied: Pillow in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (11.0.0)\n",
      "Requirement already satisfied: torch>=1.4 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from diffusers[torch]) (2.5.1)\n",
      "Collecting accelerate>=0.31.0 (from diffusers[torch])\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch>=1.4->diffusers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch>=1.4->diffusers[torch]) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch>=1.4->diffusers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.4->diffusers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from importlib_metadata->diffusers[torch]) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->diffusers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->diffusers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->diffusers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->diffusers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from jinja2->torch>=1.4->diffusers[torch]) (3.0.2)\n",
      "Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.1/9.7 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 11.0 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 22.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, accelerate, transformers\n",
      "Successfully installed accelerate-1.2.1 tokenizers-0.21.0 transformers-4.48.0\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers[\"torch\"] transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__getattr__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 사전 훈련된 모델 로드\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/stable-diffusion-v1-5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 생성 과정 실행 (여기서는 이미지 생성 예시)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA photograph of an astronaut riding a horse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py:816\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# 4. Define expected modules given pipeline signature\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# and define non-None initialized modules (=`init_kwargs`)\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# some modules can be passed directly to the init\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;66;03m# in this case they are already instantiated in `kwargs`\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# extract them here\u001b[39;00m\n\u001b[0;32m    815\u001b[0m expected_modules, optional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_signature_keys(pipeline_class)\n\u001b[1;32m--> 816\u001b[0m expected_types \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_signature_types\u001b[49m()\n\u001b[0;32m    817\u001b[0m passed_class_obj \u001b[38;5;241m=\u001b[39m {k: kwargs\u001b[38;5;241m.\u001b[39mpop(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m expected_modules \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[0;32m    818\u001b[0m passed_pipe_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs\u001b[38;5;241m.\u001b[39mpop(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m optional_kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n",
      "File \u001b[1;32md:\\01_Programming\\100_HugoBank\\Mine\\works-need-it-python\\snd_env\\lib\\site-packages\\diffusers\\utils\\import_utils.py:701\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, key):\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_load_connected_pipes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 701\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m(\u001b[38;5;28mcls\u001b[39m, key)\n\u001b[0;32m    702\u001b[0m     requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__getattr__'"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# 사전 훈련된 모델 로드\n",
    "model_id = \"./data/stable-diffusion-v1-5\"\n",
    "pipeline = DiffusionPipeline.from_pretrained(model_id)\n",
    "\n",
    "# 생성 과정 실행 (여기서는 이미지 생성 예시)\n",
    "prompt = \"A photograph of an astronaut riding a horse\"\n",
    "image = pipeline(prompt).images[0]\n",
    "\n",
    "# 생성된 이미지 저장\n",
    "image.save(\"astronaut_riding_a_horse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mxnet: Apache의 오픈소스 딥러닝 프레임워크\n",
    "\n",
    "- https://mxnet.apache.org/\n",
    "\n",
    "Apache Software Foundation에서 관리하는 오픈소스 딥러닝 프레임워크\n",
    "\n",
    "```shell\n",
    "pip install mxnet\n",
    "\n",
    "or\n",
    "\n",
    "pip install mxnet-cu101  # CUDA 10.1 버전을 사용하는 경우\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "!pip install mxnet\n",
    "## 실패!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timm: PyTorch 이미지 모델들\n",
    "\n",
    "- https://huggingface.co/docs/timm/index\n",
    "\n",
    " (PyTorch Image Models) 라이브러리는 다양한 이미지 분류, 객체 탐지, 이미지 생성 작업을 위한 사전 훈련된 모델 및 모델 구조를 포함하는 Python 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.13-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: torch in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from timm) (2.5.1)\n",
      "Collecting torchvision (from timm)\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pyyaml in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from timm) (0.27.1)\n",
      "Requirement already satisfied: safetensors in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: filelock in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from torchvision->timm) (11.0.0)\n",
      "Requirement already satisfied: colorama in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\01_programming\\100_hugobank\\mine\\works-need-it-python\\snd_env\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
      "Downloading timm-1.0.13-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 33.8 MB/s eta 0:00:00\n",
      "Using cached torchvision-0.20.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: torchvision, timm\n",
      "Successfully installed timm-1.0.13 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 309\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 사전 훈련된 모델 로드\n",
    "model = timm.create_model('resnet34', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img = Image.open(\"../../images/flower.png\")\n",
    "img = transform(img).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# 이미지 분류 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model(img)\n",
    "    _, preds = outputs.max(1)\n",
    "    print(f\"Predicted label: {preds.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformers: Hugging Face팀의 ML 라이브러리\n",
    "\n",
    "- https://huggingface.co/docs/transformers/index\n",
    "\n",
    "Hugging Face 팀이 개발한 파이썬 라이브러리로, 자연어 처리(NLP) 분야에서 널리 사용되는 Transformer 모델을 쉽게 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a calcurator?\n",
      "\n",
      "A calcurator is a device that allows you to measure the temperature of a fluid. It is used to measure the temperature of a fluid by measuring the temperature of the fluid.\n",
      "\n",
      "Calculating the temperature of a fluid\n",
      "\n",
      "Calculating the temperature of a fluid is a simple process. You can use a calculator to calculate the temperature of a fluid.\n",
      "\n",
      "Calculating the temperature of a fluid is a simple process. You can\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer  \n",
    "import torch  \n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")  \n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")  \n",
    "\n",
    "input_text = \"What is a calcurator?\"  \n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')  \n",
    "attention_mask = torch.ones(input_ids.shape)  # 모든 토큰에 주의를 기울이도록 설정  \n",
    "\n",
    "# pad_token_id 설정  \n",
    "model.config.pad_token_id = model.config.eos_token_id  \n",
    "\n",
    "output = model.generate(input_ids,  \n",
    "                        attention_mask=attention_mask,  \n",
    "                        max_length=100,  \n",
    "                        num_return_sequences=1)  \n",
    "text = tokenizer.decode(output[0], skip_special_tokens=True)  \n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
